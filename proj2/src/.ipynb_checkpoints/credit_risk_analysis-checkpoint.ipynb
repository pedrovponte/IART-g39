{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto desenvolvido por:\n",
    "* Mariana Ramos - up201806869\n",
    "* Pedro Ferreira - up201806506\n",
    "* Pedro Ponte - up201809694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "\n",
    "2. [Required Libraries](#Required-Libraries)\n",
    "\n",
    "3. [Step 1: Answering the question](#Step-1:-Answering-the-question)\n",
    "\n",
    "4. [Step 2: Checking the data](#Step-2:-Checking-the-data)\n",
    "\n",
    "5. [Step 3: Tidying the data](#Step-3:-Tidying-the-data)\n",
    "\n",
    "6. [Step 4: Exploratory Analysis](#Step-4:-Exploratory-Analysis)\n",
    "\n",
    "7. [Step 5: Classification](#Step-5:-Classification)\n",
    "\n",
    "    - [5.1: Decision Trees](#5.1:-Decision-Trees)\n",
    "\n",
    "        - [5.1.1: Parameter Tuning](#5.1.1:-Parameter-Tuning)\n",
    "    \n",
    "    - [5.2: K-Nearest Neighbor](#5.2:-K-Nearest-Neighbor)\n",
    "        \n",
    "        - [5.2.1: Parameter Tuning](#5.2.1:-Parameter-Tuning)\n",
    "        \n",
    "    - [5.3: Support-Vector Machines](#5.3:-Support-Vector-Machines)\n",
    "        \n",
    "        - [5.3.1: Parameter Tuning](#5.3.1:-Parameter-Tuning)\n",
    "        \n",
    "    - [5.4: Neural Networks](#5.4:-Neural-Networks)\n",
    "        \n",
    "        - [5.4.1: Parameter Tuning](#5.4.1:-Parameter-Tuning)\n",
    "        \n",
    "8. [Step 6: Results Analysis](#Step-6:-Results-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "If you don't have Python on your computer, you can use the [Anaconda Python distribution](http://continuum.io/downloads) to install most of the Python packages you need. Anaconda provides a simple double-click installer for your convenience.\n",
    "\n",
    "This notebook uses several Python packages that come standard with the Anaconda Python distribution. The primary libraries that we'll be using are:\n",
    "\n",
    "* **NumPy**: Provides a fast numerical array structure and helper functions.\n",
    "* **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
    "* **scikit-learn**: The essential Machine Learning package in Python.\n",
    "* **matplotlib**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "* **Seaborn**: Advanced statistical plotting library.\n",
    "* **Plotly**: Tables\n",
    "\n",
    "To make sure you have all of the packages you need, install them with `conda`:\n",
    "\n",
    "    conda install numpy pandas scikit-learn matplotlib seaborn\n",
    "    \n",
    "    conda install -c conda-forge watermark\n",
    "\n",
    "`conda` may ask you to update some of them if you don't have the most recent version. Allow it to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Answering the question\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "The first step to any data analysis project is to define the question or problem we're looking to solve, and to define a measure (or set of measures) for our success at solving that task. The data analysis checklist has us answer a handful of questions to accomplish that, so let's work through those questions.\n",
    "\n",
    ">Did you specify the type of data analytic question (e.g. exploration, association causality) before touching the data?\n",
    "\n",
    "We're trying to design a predictive model in order to evaluate the credit risk of a given loan and decide whether the loan should be granted or not.\n",
    "\n",
    ">Did you define the metric for success before beginning?\n",
    "\n",
    "Let's do that now. Since we're performing classification, we can use [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision) — the fraction of correctly classified loans — to quantify how well our model is performing. The accuracy achieved should be, at least, \n",
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Checking the data\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "In order to be able to make conclusions and reach our goal, we will need to extract and study the data. To do so, we have to import the panda library and extract the information to be stored in a variable so we can work with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.tree as tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "credit_data = pd.read_csv('data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame shape\n",
    "print('Number of rows: ', credit_data.shape[0])\n",
    "print('Number of columns: ', credit_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the data file has a total of 855969 different results and a total of 73 evaluation criteria. The second parameter of the read_csv function makes all the empty fields be filled with NA so we can easily analyse missing values in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by reading the data into a pandas DataFrame to see if is everything alright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "credit_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "credit_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the structure of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data frame columns\n",
    "credit_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame summary\n",
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some features have missing values. Let's take a closer look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# percentage of missing values per feature\n",
    "print((credit_data.isnull().sum() * 100 / credit_data.shape[0]).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.isnull().sum().plot(kind='bar', figsize=(18,8), fontsize=14,);\n",
    "plt.ylabel('Null values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tidying the data\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to all features and the respective percentage of missing values, we can conclude that some of them (like *verification_status_joint*, *annual_inc_joint*, *dti_joint*, *il_util*, *mths_since_rcnt_il*, *total_bal_il*, *inq_last_12m*, *open_acc_6m*, *open_il_6m*, *open_il_24m*, *open_il_12m*, *open_rv_12m*, *open_rv_24m*, *max_bal_bc*, *all_util*, *inq_fi*, *total_cu_tl* have almost all entries missing. As this feature is not crucial for the project, we are dropping it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns\n",
    "credit_data.drop(['verification_status_joint', 'annual_inc_joint', 'dti_joint', 'il_util', 'mths_since_rcnt_il',\n",
    "                   'total_bal_il', 'inq_last_12m', 'open_acc_6m', 'open_il_6m', 'open_il_24m', 'open_il_12m', 'open_rv_12m',\n",
    "                   'open_rv_24m', 'max_bal_bc', 'all_util', 'inq_fi', 'total_cu_tl'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the number of unique values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique observations per column\n",
    "credit_data.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature *policy_code* only has one value, so we can conclude that this one is not important for our analysis and we can also drop this collumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column \"policy_code\"\n",
    "credit_data.drop('policy_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*id* and *member_id* features are randomly generated fields by bank for unique identification purposes only, so we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns \"id\" and \"member_id\"\n",
    "credit_data.drop(['id', 'member_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features like *funded_amnt*, *funded_amnt_inv*, *mths_since_last_record*, *out_prncp*, *out_prncp_inv*, *total_pymnt*, *total_pymnt_inv*, *total_rec_prncp*, *total_rec_int*, *total_rec_late_fee*, *recoveries*, *collection_recovery_fee*, *last_pymnt_d*, *last_pymnt_amnt*, *next_pymnt_d* can be dropped because they leak data from future, after the loan has already started to be funded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "credit_data.drop(['funded_amnt', 'funded_amnt_inv', 'mths_since_last_record', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
    "                   'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', \n",
    "                   'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*emp_title* feature requires other data and a lot of processing to become potentially useful, so we opt to drop that one too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"emp_title\" column\n",
    "credit_data.drop('emp_title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also *desc*, *initial_list_status*, *total_rev_hi_lim* features doesn't add value to our model, so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"desc\", \"initial_list_status\", \"total_rev_hi_lim\" columns\n",
    "credit_data.drop(['desc', 'initial_list_status', 'total_rev_hi_lim'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*zip_code* feature is mostly redundant since only the first 3 digits of the 5 digit zip code are visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"zip_code\" column\n",
    "credit_data.drop('zip_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*addr_state* collumn seems like to contain categorical values. Let's explore the unique value counts of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(credit_data['addr_state'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *addr_state* column contains too many unique values, so it’s better to drop this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"addr_state\" column\n",
    "credit_data.drop('addr_state', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at *pymnt_plan* feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(credit_data['pymnt_plan'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this column has two unique values, *y* and *n*, with *y* occurring only 5 times. Let’s drop this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"pymnt_plan\" column\n",
    "credit_data.drop('pymnt_plan', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at *application_type* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(credit_data['application_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this column only has two unique values, *INDIVIDUAL* and *JOINT*, with *JOINT* occurring only 442 times. Let's drop this column too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"application_type\" column\n",
    "credit_data.drop('application_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s look at the unique value counts for the *purpose* and *title* columns to understand which columns we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['purpose','title']:\n",
    "    print(\"Unique Values in column: {}\\n\".format(name))\n",
    "    print(credit_data[name].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the *purpose* and *title* columns do contain overlapping information. *title* column contains too many different values with distinct information, so it is hard to analyse its values. On the other hand, *purpose* has many unique values and they are nominal so, to convert them to numerical in order to analyse them will create many new collumns and difficult our job.\n",
    "Taking this into account, we opt to drop both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"title\" and \"purpose\" column\n",
    "credit_data.drop(['title', 'purpose'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the features that we still have, we see that we have two that are very similar: *grade* and *sub_grade*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['grade','sub_grade']:\n",
    "    print(\"Unique Values in column: {}\\n\".format(name))\n",
    "    print(credit_data[name].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that *sub_grade* contains redundant information that is already in the *grade* column, so we can also drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"sub_grade\" column\n",
    "credit_data.drop('sub_grade', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = credit_data.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*mths_since_last_major_derog* column has to many null values, in the order of 75%, so we will drop this one to. We also drop *mths_since_last_delinq* column as it has a high  percentage of null valuess too, in order of 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"mths_since_last_major_derog\" and \"mths_since_last_delinq\" columns\n",
    "credit_data.drop(['mths_since_last_major_derog', 'mths_since_last_delinq'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now investigate columns that are of the **object** data type and figure out how we can make those values numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns_df = credit_data.select_dtypes(include=['object'])\n",
    "print(object_columns_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns seem to represent categorical values:\n",
    "    * term\n",
    "    * grade\n",
    "    * emp_length\n",
    "    * home_ownership\n",
    "    * verification_status\n",
    "    * earliest_cr_line\n",
    "    * last_credit_pull_d\n",
    "    * issue_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore the other categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['term', 'grade', 'emp_length', 'home_ownership', 'verification_status']\n",
    "for name in cols:\n",
    "    print(name,':')\n",
    "    print(credit_data[name].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*grade*, *emp_length* and *term* columns contain ordinal values, i.e. they are in natural order and we can sort or order them either in increasing or decreasing order. For this reason, we can change the values of this columns to the appropriate numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip months from 'term' and make it an int\n",
    "credit_data['term'] = credit_data['term'].str.split(' ').str[1]\n",
    "\n",
    "\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    },\n",
    "    \"grade\": {\n",
    "        \"A\": 1,\n",
    "        \"B\": 2,\n",
    "        \"C\": 3,\n",
    "        \"D\": 4,\n",
    "        \"E\": 5,\n",
    "        \"F\": 6,\n",
    "        \"G\": 7\n",
    "    },\n",
    "    \"term\": {\n",
    "        \"36\": 36.0,\n",
    "        \"60\": 60.0\n",
    "    }\n",
    "}\n",
    "credit_data = credit_data.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data[['emp_length', 'grade', 'term']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*verification_status* and *home_ownership* features contain nominal values, so we can't order them. In this case, we will have to convert them to numerical values using dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting nominal features into numerical features by encoding them as dummy variables\n",
    "nominal_columns = [\"verification_status\", \"home_ownership\"]\n",
    "dummy_loan = pd.get_dummies(credit_data[nominal_columns])\n",
    "print(dummy_loan.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the dummy variables into the original DataFrame, drop nominal columns\n",
    "credit_data = pd.concat([credit_data, dummy_loan], axis=1)\n",
    "credit_data = credit_data.drop(nominal_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*earliest_cr_line*, *issue_d*, *last_credit_pull_d* columns contain date values. Let's convert them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date inputs\n",
    "cols = [\"earliest_cr_line\",\"issue_d\",\"last_credit_pull_d\"]\n",
    "for col in cols:\n",
    "    credit_data[col] = pd.to_datetime(credit_data[col],format=\"%d-%m-%Y\")\n",
    "credit_data[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check if still exist columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = credit_data.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are some missing values, let's deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing values for 'revol_util' with the median 'revol_util'.\n",
    "credit_data.revol_util.fillna(credit_data.revol_util.median(), inplace=True)\n",
    "\n",
    "# Fill in the missing values for 'collections_12_mths_ex_med' with the median 'collections_12_mths_ex_med'.\n",
    "credit_data.collections_12_mths_ex_med.fillna(credit_data.collections_12_mths_ex_med.median(), inplace=True)\n",
    "\n",
    "# Fill in the missing values for 'tot_coll_amt' with the median 'tot_coll_amt'.\n",
    "credit_data.tot_coll_amt.fillna(credit_data.tot_coll_amt.median(), inplace=True)\n",
    "\n",
    "# Fill in the missing values for 'tot_cur_bal' with the median 'tot_cur_bal'.\n",
    "credit_data.tot_cur_bal.fillna(credit_data.tot_cur_bal.median(), inplace=True)\n",
    "\n",
    "# Fill in the missing values for 'emp_length' with the 0.\n",
    "credit_data.emp_length.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = credit_data.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "credit_data = credit_data.dropna()\n",
    "print(credit_data.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory Analysis\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap on the correlations between features in the loan data\n",
    "credit_correlations = credit_data.corr()\n",
    "plt.figure(figsize=(20, 20,))\n",
    "plt.imshow(credit_correlations, cmap=None, interpolation='none', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(credit_correlations)), credit_correlations.columns, rotation='vertical')\n",
    "plt.yticks(range(len(credit_correlations)), credit_correlations.columns);\n",
    "plt.suptitle('Loan correlations Heat Map', fontsize=30, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation is finished and we can now start to apply machine learning algorithms in order to predict the credit risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually better to visualize the data in some way. Visualization makes outliers and errors immediately stand out, whereas they might go unnoticed in a large table of numbers.\n",
    "As the dataset contains to many rows, first we need to get a subset of the original dataset in order to be possiblle to apply the supervised learning algorithms to test our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Classification\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "To advance to the data analysis we need to gather the test and the train samples. To do so we will import the function train_test_split from sklearn and use it on thecredit_data data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data_subset = credit_data.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the subset is not balanced (has more 0 in *default_ind* than 1), we need to balance it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ind_0 = credit_data_subset.loc[credit_data_subset['default_ind'] == 0]\n",
    "default_ind_1 = credit_data_subset.loc[credit_data_subset['default_ind'] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(default_ind_1, replace=True, n_samples=len(default_ind_0),random_state=123)\n",
    "\n",
    "credit_data_subset = pd.concat([default_ind_0, df_minority_upsampled])\n",
    "\n",
    "credit_data_subset.default_ind.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset contains to many rows, first we need to get a subset of the original dataset in order to be possiblle to apply the supervised learning algorithms to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_data_subset[credit_data_subset.columns.drop(['default_ind', 'issue_d', 'earliest_cr_line', 'last_credit_pull_d', 'dti',\n",
    "                                                        'inq_last_6mths', 'revol_util', 'collections_12_mths_ex_med', 'home_ownership_ANY',\n",
    "                                                       'delinq_2yrs'])] \n",
    "y = credit_data_subset['default_ind']\n",
    "\n",
    "# get a test dataset with 20% of the credit_data_subset\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()\n",
    "print()\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Decision Trees\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "dtc_prediction = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "dtc_classification_report = classification_report(y_test, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(f\"Classification report:\\n{classification_report(y_test, dtc_prediction)}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_dtc = confusion_matrix(y_test, dtc_prediction)\n",
    "\n",
    "sb.heatmap(confusion_matrix_dtc, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1: Parameter Tuning\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Every Machine Learning model comes with a variety of parameters to tune, and these parameters can be vitally important to the performance of our classifier.\n",
    "\n",
    "The most common method for model parameter tuning is Grid Search. The idea behind Grid Search is simple: explore a range of parameters and find the best-performing parameter combination. Focus your search on the best range of parameters, then repeat this process several times until the best parameters are discovered.\n",
    "\n",
    "Let's tune our decision tree classifier. Let's start by tuning only two parameters and analyse the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                  'splitter': ['best', 'random'],\n",
    "                  'max_depth': range(10, 20),\n",
    "                  'max_features': range(10,20)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "print('Best estimator: {}'.format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = grid_search.best_estimator_\n",
    "dtc_prediction = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "best_dtc_classification_report = classification_report(y_test, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved model ---\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(y_test, dtc_prediction)}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_dtc = confusion_matrix(y_test, dtc_prediction)\n",
    "\n",
    "sb.heatmap(confusion_matrix_dtc, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the best classifier, that allows our model to achieve a score of aproximately 94%.\n",
    "\n",
    "We can also visualize the Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(decision_tree_classifier)\n",
    "plt.figure(figsize=(15, 150))\n",
    "plt.show()\n",
    "\n",
    "with open('iris_dtc.dot', 'w') as out_file:\n",
    "    out_file = tree.export_graphviz(decision_tree_classifier, out_file=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: K-Nearest Neighbor\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "The K-Nearest Neighbors algorithm (k-NN) is a non-parametric classification method. The input consists of the k closest training examples in data set. The output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "\n",
    "Let's start to apply this algorithmn to our model with k=5 and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "knn_prediction = knn.predict(X_test)\n",
    "\n",
    "knn_classification_report = classification_report(y_test, knn_prediction, output_dict=True)\n",
    "\n",
    "print(f\"Classification report:\\n{classification_report(y_test, knn_prediction, labels=np.unique(y_train))}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_knn = confusion_matrix(y_test, knn_prediction)\n",
    "\n",
    "sb.heatmap(confusion_matrix_knn, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1: Parameter Tunning\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'n_neighbors': [5,10,15,20],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           scoring='precision_weighted',\n",
    "                           cv=10,\n",
    "                           n_jobs=3,\n",
    "                           verbose=4)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "yk_pred = knn.predict(X_test)\n",
    "\n",
    "best_knn_classification_report = classification_report(y_test, yk_pred, output_dict=True)\n",
    "\n",
    "print(\"--- Improved model ---\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(y_test, yk_pred)}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_knn = confusion_matrix(y_test, yk_pred)\n",
    "\n",
    "sb.heatmap(confusion_matrix_knn, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Support-Vector Machines\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Support Vector Machines (SVMs) are a powerful supervised learning algorithm used for classification or for regression. SVMs are a discriminative classifier: that is, they draw a boundary between clusters of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "svc_prediction = svc.predict(X_test)\n",
    "\n",
    "svm_classification_report = classification_report(y_test, svc_prediction, output_dict=True)\n",
    "\n",
    "print(f\"Classification report:\\n{classification_report(y_test, svc_prediction)}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_svm = confusion_matrix(y_test, svc_prediction)\n",
    "\n",
    "sb.heatmap(confusion_matrix_svm, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()\n",
    "\n",
    "best_svm_classification_report = svm_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1: Parameter Tunning\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'C' : [0.1, 1, 10], \n",
    "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=4,\n",
    "                           n_jobs=4)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "yk_pred = svc.predict(X_test)\n",
    "\n",
    "best_svm_classification_report = classification_report(y_test, yk_pred, output_dict=True)\n",
    "\n",
    "print(\"--- Improved model ---\\n\")\n",
    "print(f\"Classification report:\\n{best_knn_classification_report(y_test, yk_pred)}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_svm = confusion_matrix(y_test, yk_pred)\n",
    "\n",
    "sb.heatmap(confusion_matrix_svm, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4: Neural Networks\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, either organic or artificial in nature. Neural networks can adapt to changing input; so the network generates the best possible result without needing to redesign the output criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_nn = scaler.transform(X_train)\n",
    "X_test_nn = scaler.transform(X_test)\n",
    "\n",
    "# Create the classifier\n",
    "ANNClassifier = MLPClassifier(random_state=1, max_iter=500)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "ANNClassifier.fit(X_train_nn, y_train)\n",
    "\n",
    "predictions = ANNClassifier.predict(X_test_nn)\n",
    "\n",
    "confusion_matrix_ann = confusion_matrix(y_test,predictions)\n",
    "\n",
    "nn_classification_report = classification_report(y_test, predictions, output_dict=True)\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "sb.heatmap(confusion_matrix_ann, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()\n",
    "\n",
    "best_nn_classification_report = nn_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.1: Parameter Tunning\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'activation': ['tanh','identity','logistic','relu'],\n",
    "                  'solver': ['adam','lbfgs','sgd'],\n",
    "                  'hidden_layer_sizes': [3,5,8,13,21,34],\n",
    "                  'verbose': [True]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid_search = GridSearchCV(ANNClassifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "print('Best estimator: {}'.format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNClassifier = grid_search.best_estimator_\n",
    "yk_pred = ANNClassifier.predict(X_test)\n",
    "\n",
    "best_nn_classification_report = classification_report(y_test, yk_pred, output_dict=True)\n",
    "\n",
    "print(\"--- Improved model ---\\n\")\n",
    "print(f\"Classification report:\\n{best_nn_classification_report(y_test, yk_pred)}\\n\")\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "confusion_matrix_ann = confusion_matrix(y_test, yk_pred)\n",
    "\n",
    "sb.heatmap(confusion_matrix_ann, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Results Analysis\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "algorithms_data = [\n",
    "    [dtc_classification_report['accuracy'], knn_classification_report['accuracy'], svm_classification_report['accuracy'], nn_classification_report['accuracy']],\n",
    "    [best_dtc_classification_report['accuracy'], best_knn_classification_report['accuracy'], best_svm_classification_report['accuracy'], best_nn_classification_report['accuracy']]\n",
    "]\n",
    "\n",
    "X = np.arange(4)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X+0.0, algorithms_data[0], width=0.25, tick_label=['DTC', 'KNN', 'SVM', 'NN'], color = 'b')\n",
    "ax.bar(X+0.25, algorithms_data[1], width=0.25, color = 'c')\n",
    "\n",
    "original = mpatches.Patch(color='b', label='Original')\n",
    "improved = mpatches.Patch(color='c', label='Improved')\n",
    "\n",
    "plt.legend(handles=[original, improved], bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms_data = [\n",
    "    [best_dtc_classification_report['accuracy'], best_knn_classification_report['accuracy'], best_svm_classification_report['accuracy'], best_nn_classification_report['accuracy']],\n",
    "    [best_dtc_classification_report['f1-score'], best_knn_classification_report['f1-score'], best_svm_classification_report['f1-score'], best_nn_classification_report['f1-score']],\n",
    "    [best_dtc_classification_report['precision'], best_knn_classification_report['precision'], best_svm_classification_report['precision'], best_nn_classification_report['precision']]\n",
    "]\n",
    "\n",
    "X = np.arange(4)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X+0.0, algorithms_data[0], width=0.25, color = 'b')\n",
    "ax.bar(X+0.25, algorithms_data[1], width=0.25, tick_label=['DTC', 'KNN', 'SVM', 'NN'], color = 'g')\n",
    "ax.bar(X+0.50, algorithms_data[2], width=0.25, color = 'y')\n",
    "\n",
    "accuracy = mpatches.Patch(color='b', label='accuracy')\n",
    "f1_score = mpatches.Patch(color='g', label='f1-score')\n",
    "precision = mpatches.Patch(color='y', label='precision')\n",
    "\n",
    "\n",
    "plt.legend(handles=[original, improved], bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = go.Figure(data=[go.Table(header=dict(values=['Algorithm', 'Accuracy Normal', 'Accuracy Improved']),\n",
    "                 cells=dict(values=[algs, [dtc_classification_report['accuracy'], knn_classification_report['accuracy'], svm_classification_report['accuracy'], nn_classification_report['accuracy']], \n",
    "                                   [best_dtc_classification_report['accuracy'], best_knn_classification_report['accuracy'], best_svm_classification_report['accuracy'], best_nn_classification_report['accuracy']]]))\n",
    "                     ])\n",
    "table.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
